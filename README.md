# Federated-Learning-with-Attack-Detection
Built a federated learning framework with 10 simulated clients on MNIST, preserving privacy during distributed training.
•Simulated adversarial clients submitting falsified updates and introduced a deviation-based detection method to isolate malicious behavior.
•Applied robust aggregation (Krum, Median, Trimmed Mean), maintaining 98.96% global model accuracy under adversarial conditions.
•Tools: Python, PyTorch, CNNs, Federated Averaging, Robust ML
